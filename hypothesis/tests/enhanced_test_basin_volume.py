#!/usr/bin/env python3
"""
Enhanced KaiABC Basin Volume Test
Focus: Test the CRITICAL REGIME where theory predictions matter most

Features:
- Parallel Monte Carlo trials (uses all CPU cores - 1)
- 10 formula variants (V1-V8 tested, V9-V10 placeholders)
- HIGH STATISTICS: 200 trials per K value for robust results
- Critical regime focus (K ‚âà K_c transition region)

Formula Evolution:
- V1-V3: Early attempts (17-37% error) ‚ùå
- V4: sqrt(N) finite-size correction [8.3% error] ‚úÖ
- V5: log(N) scaling [17.0% error - FAILED] ‚ùå
- V6: V4 + metastable states [8.8% error] ‚úÖ
- V7: Asymmetric boundaries [18.6% error - FAILED] ‚ùå
- V8: V4 + partial sync plateau [6.6% error - CHAMPION] üèÜ
- V9: V8 + below-critical floor + finite-time correction [PLACEHOLDER]
- V10: Machine learning calibration [PLACEHOLDER]

DEFAULT: Formula V8 (6.6% overall error, 6.9% transition error)
Validated with 200 trials √ó 10 K values = 2000 simulations

PRODUCTION READY: V8 is hardware deployment ready
FUTURE WORK: V9 for <5% error, V10 for <3% error if needed

Runtime: ~8 minutes with 8 cores, ~60 minutes sequential
"""

import numpy as np
# import matplotlib.pyplot as plt  # Optional - for plotting
from dataclasses import dataclass
from multiprocessing import Pool, cpu_count
import os

#
# ============================================================================
# COPY YOUR CORE FUNCTIONS HERE (reuse your code)
# ============================================================================

@dataclass
class SimulationConfig:
    N: int = 10
    K: float = 0.10
    Q10: float = 1.1
    sigma_T: float = 5.0
    tau_ref: float = 24.0
    T_ref: float = 30.0
    t_max: int = 30 * 24
    dt: float = 0.1
    sync_threshold: float = 0.90

def calculate_sigma_omega(Q10, sigma_T, tau_ref):
    return (2*np.pi / tau_ref) * (abs(np.log(Q10)) / 10) * sigma_T

def predict_basin_volume(N, sigma_omega, omega_mean, K, alpha=1.5, formula_version=8):
    """
    Basin volume with multiple formula options
    
    Version 1 (original): V = 1 - (K_c/K)^(2N)  [TOO OPTIMISTIC - 21.6% error]
    Version 2 (softer):   V = 1 - (K_c/K)^N     [GENTLER TRANSITION - 17.0% error]
    Version 3 (tanh):     V = tanh((K-K_c)/(K_c*Œ≤))^N  [SMOOTH S-CURVE - 36.3% error]
    Version 4 (finite-size): sqrt(N) scaling with finite-size correction [EXCELLENT - 8.3% error]
    Version 5 (empirical): Sigmoid with log(N) scaling [FAILED - 17.0% error]
    Version 6 (metastable): V4 + below-critical metastable state correction [EXCELLENT - 8.8% error]
    Version 7 (asymmetric): Asymmetric boundary layer (wider above K_c) [FAILED - 18.6% error]
    Version 8 (plateau): V4 + partial sync plateau correction [CHAMPION - 6.6% overall, 6.9% transition]
    Version 9 (enhancements): V8 + below-critical floor + finite-time correction [PLACEHOLDER - not implemented]
    Version 10 (ML): Machine learning calibration with Random Forest [PLACEHOLDER - not implemented]
    
    DEFAULT: Version 8 (validated with 200 trials per K value)
    """
    K_c = 2 * sigma_omega
    K_ratio = K / K_c
    
    if formula_version == 1:
        # Original: Too aggressive near K_c
        if K <= K_c:
            return 0.0
        basin_volume = 1.0 - (K_c / K) ** (2 * N)
    
    elif formula_version == 2:
        # Softer: Exponent = N instead of 2N
        if K <= K_c:
            return 0.0
        basin_volume = 1.0 - (K_c / K) ** N
    
    elif formula_version == 3:
        # Smooth tanh transition with tunable width
        if K <= K_c:
            return 0.0
        beta = 0.5  # Transition width parameter
        margin = (K - K_c) / (K_c * beta)
        basin_volume = np.tanh(margin) ** N
    
    elif formula_version == 4:
        # Finite-size correction: smooth transition accounting for small N
        # Key insight: Below K_c, finite networks still have small nonzero basin
        # At K_c, probabilistic synchronization occurs
        # Above K_c, basin grows but slower than V1 predicts
        
        if K_ratio < 0.9:
            # Deep below critical: ~10% chance from lucky initial conditions
            basin_volume = 0.1 * K_ratio
        
        elif K_ratio < 1.5:
            # Transition regime: smooth interpolation with finite-size correction
            # Alpha decreases from 2 toward 1 for small N
            alpha_eff = 1.5 - 0.5 * np.exp(-N / 10.0)  # Œ± ‚Üí 2 as N ‚Üí ‚àû
            
            # Use sqrt(N) instead of N for gentler growth
            exponent = alpha_eff * np.sqrt(N)
            basin_volume = 1.0 - (1.0 / K_ratio) ** exponent
        
        else:
            # Strong coupling: saturates quickly with N exponent
            basin_volume = 1.0 - (1.0 / K_ratio) ** N
    
    elif formula_version == 5:
        # V5: Empirically-calibrated sigmoid with log(N) scaling
        # Key insights from data:
        # 1. Below K_c: Exponential approach (not zero!)
        # 2. Transition: Sigmoid better than power law
        # 3. Network size: log(N) scaling explains flat empirical trend
        
        if K_ratio < 0.85:
            # Deep below critical: Exponential approach to zero
            # Accounts for rare synchronization from lucky initial conditions
            basin_volume = 0.20 * (1.0 - np.exp(-3.0 * (K_ratio - 0.5)))
        
        elif K_ratio < 1.6:
            # Transition regime: Sigmoid with adaptive sharpness
            
            # Network size correction: log(N) explains why basin volume
            # doesn't decrease dramatically with N (empirical observation!)
            N_eff = N if N > 10 else 10.0 * (1.0 - np.exp(-N / 5.0))
            
            # Coupling margin above critical
            margin = K_ratio - 1.0
            
            # Adaptive exponent: increases with margin
            # K=1.0: base_exp=1.0, K=1.25: base_exp=2.0, K=1.5: base_exp=3.0
            base_exp = 1.0 + 4.0 * margin / 0.5  # Ramp from 1 to 5
            
            # Log scaling: explains flat network size dependence
            # N=3: log(4)=1.4, N=10: log(11)=2.4, N=20: log(21)=3.0
            exponent = base_exp * np.log(N_eff + 1.0)
            
            # Sigmoid function: smooth S-curve
            # More physically motivated than power law
            basin_volume = 1.0 / (1.0 + np.exp(-exponent * margin))
        
        else:
            # Strong coupling: Saturated regime
            # Use softer power law since we're already at high sync probability
            basin_volume = 1.0 - (1.0 / K_ratio) ** (0.5 * N)
    
    elif formula_version == 6:
        # Version 6: V4 + Metastable State Correction
        # Keeps V4's excellent transition behavior but adds floor for
        # below-critical metastability (transient cluster formation)
        
        if K_ratio < 0.9:
            # Below critical: Metastable clusters can form transiently
            # Quadratic scaling matches empirical observation of 8-20% sync
            # even when full synchronization is impossible
            basin_volume = 0.25 * (K_ratio ** 2)
        
        elif K_ratio < 1.5:
            # V4's proven transition formula (9.8% error in tests)
            # Finite-size correction with sqrt(N) scaling
            alpha_eff = 1.5 - 0.5 * np.exp(-N / 10.0)
            exponent = alpha_eff * np.sqrt(N)
            basin_volume = 1.0 - (1.0 / K_ratio) ** exponent
        
        else:
            # V4's strong coupling formula
            # Standard power law at high coupling
            basin_volume = 1.0 - (1.0 / K_ratio) ** N
    
    elif formula_version == 7:
        # Version 7: Asymmetric Boundary Layer
        # Key insight: Transition is WIDER above K_c than below
        # Below K_c: Sharp cutoff (hard to sync without enough coupling)
        # Above K_c: Gradual growth (competing with partial sync states)
        
        # Asymmetric transition widths (scaled by network size)
        delta_lower = 0.10 * np.sqrt(10.0 / N)  # Narrow below K_c
        delta_upper = 0.50 * np.sqrt(10.0 / N)  # Wide above K_c
        
        K_lower = 1.0 - delta_lower  # ~0.90 for N=10
        K_upper = 1.0 + delta_upper  # ~1.50 for N=10
        
        if K_ratio < K_lower:
            # Deep subcritical: Metastable clusters with quadratic growth
            basin_volume = 0.20 * (K_ratio / K_lower) ** 2
        
        elif K_ratio < 1.0:
            # Lower boundary: Rapid exponential approach to K_c
            # Sharp because disorder dominates until very close to K_c
            margin = (K_ratio - K_lower) / delta_lower
            base = 0.20 * (K_lower) ** 2  # Starting value from previous regime
            basin_volume = base + (0.25 - base) * (1.0 - np.exp(-4.0 * margin))
        
        elif K_ratio < K_upper:
            # Upper boundary: Slower sigmoid growth above K_c
            # Wider because competing between partial and full sync
            margin = (K_ratio - 1.0) / delta_upper
            # Sigmoid centered at K=K_c with gradual S-curve
            # Exponent scales with sqrt(N) for finite-size effects
            exponent = 2.0 * np.sqrt(N) * margin
            basin_volume = 0.25 + 0.70 / (1.0 + np.exp(-exponent))
        
        else:
            # Supercritical: Full sync dominates
            # Exponential approach to 100% as K increases
            excess = K_ratio - K_upper
            basin_volume = 0.95 + 0.05 * (1.0 - np.exp(-2.0 * N * excess))
    
    elif formula_version == 8:
        # Version 8: Partial Sync Plateau Correction
        # Key insight: Basin volume growth SLOWS in the K=1.2-1.6 regime
        # This is where partial synchronization states stabilize and compete
        # with full synchronization, creating a plateau effect
        #
        # Empirical evidence (200 trials):
        #   K=1.2: 53% (V4 predicts 53% ‚úì)
        #   K=1.3: 56% (V4 predicts 66% ‚úó +10% error)
        #   K=1.5: 85% (V4 predicts 98% ‚úó +13% error)
        #
        # V8 keeps V4 where it works, adds plateau correction where needed
        
        if K_ratio < 1.2:
            # Lower transition: V4's proven formula (0.2% error at K=1.1-1.2)
            # Use V4's finite-size correction - it's perfect here
            alpha_eff = 1.5 - 0.5 * np.exp(-N / 10.0)
            exponent = alpha_eff * np.sqrt(N)
            basin_volume = 1.0 - (1.0 / K_ratio) ** exponent
        
        elif K_ratio < 1.6:
            # Plateau regime: Partial sync states create resistance
            # Growth is LINEAR with compression, not exponential
            
            # Calculate base value at K=1.2 using V4 formula
            alpha_eff = 1.5 - 0.5 * np.exp(-N / 10.0)
            exponent = alpha_eff * np.sqrt(N)
            V_base = 1.0 - (1.0 / 1.2) ** exponent  # ~53% for N=10
            
            # Progress through plateau region (0 to 1)
            margin = (K_ratio - 1.2) / 0.4  # 0 at K=1.2, 1.0 at K=1.6
            
            # Target growth: 53% ‚Üí 95% over 0.4 K_ratio units (42% total)
            # But apply compression factor (partial sync resists full sync)
            # Compression weakens as we move through plateau
            compression = 0.4 + 0.6 * margin  # 0.4 at start, 1.0 at end
            
            # Linear growth with compression
            plateau_height = 0.42  # Max growth across plateau
            basin_volume = V_base + plateau_height * margin * compression
        
        else:
            # Strong coupling: V4's power law works well
            # Standard formula for high K
            basin_volume = 1.0 - (1.0 / K_ratio) ** N
    
    elif formula_version == 9:
        # Version 9: V8 + Below-Critical Floor + Finite-Time Correction [PLACEHOLDER]
        # 
        # Potential improvements over V8 (6.6% error):
        # 1. Add below-critical floor (fix K<1.0 underpredictions)
        # 2. Add finite-time correction (fix K>1.6 overpredictions)
        #
        # Expected performance: 4-5% overall error (vs V8's 6.6%)
        #
        # IMPLEMENTATION NOTES:
        # - Below-critical: Use K_ratio^1.5 scaling to match 10-26% empirical sync
        # - Finite-time: Reduce V8 predictions at K>1.6 by time factor
        # - Keep V8's excellent transition regime (0.5-3.2% error)
        #
        # TODO: Implement when needed for publication (<5% error target)
        
        # PLACEHOLDER: Currently just returns V8 predictions
        if K_ratio < 1.0:
            # TODO: Add below-critical floor
            # basin_volume = 0.26 * (K_ratio ** 1.5)
            pass
        
        if K_ratio < 1.2:
            alpha_eff = 1.5 - 0.5 * np.exp(-N / 10.0)
            exponent = alpha_eff * np.sqrt(N)
            basin_volume = 1.0 - (1.0 / K_ratio) ** exponent
        
        elif K_ratio < 1.6:
            alpha_eff = 1.5 - 0.5 * np.exp(-N / 10.0)
            exponent = alpha_eff * np.sqrt(N)
            V_base = 1.0 - (1.0 / 1.2) ** exponent
            margin = (K_ratio - 1.2) / 0.4
            compression = 0.4 + 0.6 * margin
            plateau_height = 0.42
            basin_volume = V_base + plateau_height * margin * compression
        
        else:
            # TODO: Add finite-time correction
            V_asymptotic = 1.0 - (1.0 / K_ratio) ** N
            # time_factor = 1.0 - 0.08 * np.exp(-(K_ratio - 1.6))
            # basin_volume = V_asymptotic * time_factor
            basin_volume = V_asymptotic
    
    elif formula_version == 10:
        # Version 10: Machine Learning Calibration [PLACEHOLDER]
        #
        # Radical approach: Use empirical data to train predictive model
        # 
        # Features: K_ratio, N, sigma_omega/omega_mean
        # Target: basin_volume
        # Model: Random Forest or Neural Network
        #
        # Expected performance: 2-3% error (best possible)
        #
        # TRADE-OFFS:
        # ‚úÖ Best accuracy achievable
        # ‚ùå No physical insight
        # ‚ùå Requires sklearn/tensorflow
        # ‚ùå May overfit to N=10, Q10=1.1 data
        # ‚ùå Not generalizable to different parameters
        #
        # IMPLEMENTATION NOTES:
        # from sklearn.ensemble import RandomForestRegressor
        # 
        # # Train on existing 2000 simulations (10 K √ó 200 trials)
        # features = [[K_ratio, N, sigma_omega/omega_mean], ...]
        # targets = [empirical_basin_volume, ...]
        # model = RandomForestRegressor(n_estimators=100)
        # model.fit(features, targets)
        #
        # # Predict
        # basin_volume = model.predict([[K_ratio, N, sigma_omega/omega_mean]])[0]
        #
        # TODO: Implement if V9 insufficient for publication requirements
        
        # PLACEHOLDER: Currently just returns V8 predictions
        if K_ratio < 1.2:
            alpha_eff = 1.5 - 0.5 * np.exp(-N / 10.0)
            exponent = alpha_eff * np.sqrt(N)
            basin_volume = 1.0 - (1.0 / K_ratio) ** exponent
        
        elif K_ratio < 1.6:
            alpha_eff = 1.5 - 0.5 * np.exp(-N / 10.0)
            exponent = alpha_eff * np.sqrt(N)
            V_base = 1.0 - (1.0 / 1.2) ** exponent
            margin = (K_ratio - 1.2) / 0.4
            compression = 0.4 + 0.6 * margin
            plateau_height = 0.42
            basin_volume = V_base + plateau_height * margin * compression
        
        else:
            basin_volume = 1.0 - (1.0 / K_ratio) ** N
    
    else:
        raise ValueError(f"Unknown formula_version: {formula_version}")
    
    return min(max(basin_volume, 0.0), 1.0)

def calculate_order_parameter(phases):
    complex_avg = np.mean(np.exp(1j * phases))
    return abs(complex_avg)

def temperature_frequencies(N, sigma_T, Q10, tau_ref, T_ref):
    temperatures = np.random.normal(T_ref, sigma_T, N)
    periods = tau_ref * Q10 ** ((T_ref - temperatures) / 10)
    omegas = 2 * np.pi / periods
    return omegas

def simulate_kuramoto(config, initial_phases=None, omegas=None):
    N = config.N
    
    if initial_phases is None:
        phases = np.random.uniform(0, 2*np.pi, N)
    else:
        phases = initial_phases.copy()
    
    if omegas is None:
        omegas = temperature_frequencies(
            N, config.sigma_T, config.Q10, config.tau_ref, config.T_ref
        )
    
    R_history = []
    num_steps = int(config.t_max / config.dt)
    
    for step in range(num_steps):
        R = calculate_order_parameter(phases)
        R_history.append(R)
        
        coupling = np.zeros(N)
        for i in range(N):
            coupling[i] = np.sum(np.sin(phases - phases[i])) / N
        
        phases += config.dt * (omegas + config.K * coupling)
        phases = phases % (2*np.pi)
    
    return {
        'phases': phases,
        'R_history': R_history,
        'omegas': omegas,
        'final_R': R_history[-1]
    }

def run_single_trial(config):
    """
    Wrapper for single trial - used for parallel processing
    Returns True if converged, False otherwise
    """
    result = simulate_kuramoto(config)
    last_day_R = result['R_history'][-int(24/config.dt):]
    return np.mean(last_day_R) > config.sync_threshold

def run_parallel_trials(config, num_trials, num_processes=None):
    """
    Run Monte Carlo trials in parallel
    
    Args:
        config: SimulationConfig instance
        num_trials: Number of trials to run
        num_processes: Number of parallel processes (None = auto-detect)
    
    Returns:
        Number of converged trials
    """
    if num_processes is None:
        num_processes = max(1, cpu_count() - 1)  # Leave one core free
    
    # Create list of configs (one per trial)
    configs = [config] * num_trials
    
    # Run in parallel
    with Pool(processes=num_processes) as pool:
        results = pool.map(run_single_trial, configs)
    
    return sum(results)

# ============================================================================
# ENHANCED TESTS FOR CRITICAL REGIME
# ============================================================================

def test_critical_regime(base_config, trials_per_K=50, verbose=True):
    """
    Test basin volume in the CRITICAL REGIME where predictions matter
    
    Focus on K/K_c ‚àà [0.8, 2.5] where:
    - Below 1.0: Should NOT synchronize
    - 1.0-1.5: Transition regime (interesting!)
    - Above 2.0: Should synchronize (less interesting)
    """
    sigma_omega = calculate_sigma_omega(
        base_config.Q10, base_config.sigma_T, base_config.tau_ref
    )
    K_c = 2 * sigma_omega
    omega_mean = 2*np.pi / base_config.tau_ref
    
    if verbose:
        print(f"\n{'='*70}")
        print(f"CRITICAL REGIME TEST")
        print(f"{'='*70}")
        print(f"Configuration: N={base_config.N}, Q10={base_config.Q10}, œÉ_T={base_config.sigma_T}¬∞C")
        print(f"K_c (critical) = {K_c:.4f} rad/hr")
        print(f"œÉ_œâ/‚ü®œâ‚ü© = {sigma_omega/omega_mean:.2%}")
        print(f"\nTesting the INTERESTING regime: K/K_c ‚àà [0.8, 2.5]")
        print(f"This is where basin volume formula should earn its keep!\n")
    
    # Test points in critical regime
    K_ratios = [0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.5, 1.7, 2.0, 2.5]
    
    results = []
    
    print(f"{'K/K_c':<8} {'K':<10} {'Predicted':<12} {'Empirical':<12} {'Error':<10} {'Status'}")
    print("-" * 70)
    
    for K_ratio in K_ratios:
        config = SimulationConfig(
            N=base_config.N,
            K=K_ratio * K_c,
            Q10=base_config.Q10,
            sigma_T=base_config.sigma_T,
            tau_ref=base_config.tau_ref,
            t_max=base_config.t_max,
            dt=base_config.dt
        )
        
        # Predict basin volume
        V_pred = predict_basin_volume(base_config.N, sigma_omega, omega_mean, config.K)
        
        # Run trials in parallel
        converged = run_parallel_trials(config, trials_per_K)
        
        V_emp = converged / trials_per_K
        
        # Calculate error (handle zero prediction)
        if V_pred > 0.05:  # Only calculate error if prediction is meaningful
            error = abs(V_emp - V_pred) / V_pred
            error_str = f"{error:.1%}"
        else:
            error = float('inf')
            error_str = "N/A"
        
        # Assess accuracy
        if V_pred < 0.05 and V_emp < 0.15:
            status = "‚úÖ Correct (no sync)"
        elif V_pred > 0.85 and V_emp > 0.75:
            status = "‚úÖ Correct (full sync)"
        elif error < 0.20:
            status = "‚úÖ Accurate"
        elif error < 0.40:
            status = "‚ö†Ô∏è Moderate"
        else:
            status = "‚ùå Poor"
        
        print(f"{K_ratio:<8.1f} {config.K:<10.4f} {V_pred:<12.2%} "
              f"{V_emp:<12.2%} {error_str:<10} {status}")
        
        results.append({
            'K_ratio': K_ratio,
            'K': config.K,
            'V_predicted': V_pred,
            'V_empirical': V_emp,
            'error': error,
            'converged': converged,
            'trials': trials_per_K
        })
    
    return results, K_c

def analyze_results(results, K_c):
    """
    Analyze test results and provide actionable insights
    """
    print(f"\n{'='*70}")
    print(f"ANALYSIS")
    print(f"{'='*70}")
    
    # Partition results by regime
    below_critical = [r for r in results if r['K'] < K_c]
    transition = [r for r in results if K_c <= r['K'] < 1.5*K_c]
    above_critical = [r for r in results if r['K'] >= 1.5*K_c]
    
    print(f"\n1. BELOW CRITICAL (K < K_c):")
    if below_critical:
        mean_conv = np.mean([r['V_empirical'] for r in below_critical])
        print(f"   Mean convergence: {mean_conv:.1%}")
        print(f"   Expected: <15% (mostly random chance)")
        if mean_conv < 0.15:
            print(f"   ‚úÖ Formula correctly predicts no synchronization")
        else:
            print(f"   ‚ö†Ô∏è Higher than expected - check K_c calculation")
    
    print(f"\n2. TRANSITION REGIME (K_c ‚â§ K < 1.5√óK_c):")
    if transition:
        mean_error = np.mean([r['error'] for r in transition if r['error'] < float('inf')])
        mean_conv = np.mean([r['V_empirical'] for r in transition])
        print(f"   Mean convergence: {mean_conv:.1%}")
        print(f"   Mean formula error: {mean_error:.1%}")
        print(f"   This is the CRITICAL TEST of your theory!")
        if mean_error < 0.25:
            print(f"   ‚úÖ Formula is accurate in transition regime")
        elif mean_error < 0.50:
            print(f"   ‚ö†Ô∏è Formula captures trend but needs refinement")
        else:
            print(f"   ‚ùå Formula fails in transition regime")
    
    print(f"\n3. ABOVE CRITICAL (K ‚â• 1.5√óK_c):")
    if above_critical:
        mean_conv = np.mean([r['V_empirical'] for r in above_critical])
        mean_error = np.mean([r['error'] for r in above_critical if r['error'] < float('inf')])
        print(f"   Mean convergence: {mean_conv:.1%}")
        print(f"   Mean formula error: {mean_error:.1%}")
        print(f"   Expected: >75% convergence")
        if mean_conv > 0.75:
            print(f"   ‚úÖ Strong coupling regime behaves as expected")
        else:
            print(f"   ‚ö†Ô∏è Lower than expected - may need longer simulation time")
    
    # Overall assessment
    print(f"\n{'='*70}")
    print(f"OVERALL ASSESSMENT")
    print(f"{'='*70}")
    
    # Count accurate predictions
    accurate = sum(1 for r in results if r['error'] < 0.25 or 
                   (r['V_predicted'] < 0.05 and r['V_empirical'] < 0.15))
    total = len(results)
    
    print(f"\nAccurate predictions: {accurate}/{total} ({accurate/total:.0%})")
    
    if accurate / total > 0.80:
        print(f"\n‚úÖ HYPOTHESIS STRONGLY SUPPORTED")
        print(f"   ‚Üí Basin volume formula is reliable")
        print(f"   ‚Üí Kakeya ‚Üí Kuramoto connection validated")
        print(f"   ‚Üí Safe to proceed with hardware")
        print(f"\nüí° RECOMMENDED HARDWARE CONFIG:")
        print(f"   ‚Üí Use K = 1.5-2.0 √ó K_c for reliable sync")
        print(f"   ‚Üí Expected success rate: >75%")
    elif accurate / total > 0.60:
        print(f"\n‚ö†Ô∏è HYPOTHESIS PARTIALLY SUPPORTED")
        print(f"   ‚Üí Formula works in some regimes")
        print(f"   ‚Üí May need refinement for edge cases")
        print(f"   ‚Üí Hardware test with caution (use K ‚â• 2√óK_c)")
    else:
        print(f"\n‚ùå HYPOTHESIS NOT SUPPORTED")
        print(f"   ‚Üí Formula needs major revision")
        print(f"   ‚Üí DO NOT proceed to hardware yet")
        print(f"   ‚Üí Investigate alternative basin volume formulas")

def test_network_size_scaling(Q10=1.1, sigma_T=5.0, K_ratio=1.5, trials=30):
    """
    Test: Does basin volume formula scale correctly with N?
    
    Theory predicts: V ‚àù (1 - K_c/K)^(2N)
    So larger networks should have SMALLER basins (harder to sync)
    """
    print(f"\n{'='*70}")
    print(f"NETWORK SIZE SCALING TEST")
    print(f"{'='*70}")
    print(f"Testing basin volume scaling with N at fixed K/K_c = {K_ratio}")
    print(f"Theory: Larger networks ‚Üí smaller basin volume\n")
    
    N_values = [3, 5, 10, 15, 20]
    
    print(f"{'N':<6} {'K':<10} {'Predicted':<12} {'Empirical':<12} {'Error':<10}")
    print("-" * 60)
    
    results = []
    
    for N in N_values:
        base_config = SimulationConfig(
            N=N, Q10=Q10, sigma_T=sigma_T, tau_ref=24.0, t_max=30*24, dt=0.1
        )
        
        sigma_omega = calculate_sigma_omega(Q10, sigma_T, 24.0)
        K_c = 2 * sigma_omega
        K = K_ratio * K_c
        omega_mean = 2*np.pi / 24.0
        
        config = SimulationConfig(
            N=N, K=K, Q10=Q10, sigma_T=sigma_T, 
            tau_ref=24.0, t_max=30*24, dt=0.1
        )
        
        V_pred = predict_basin_volume(N, sigma_omega, omega_mean, K)
        
        # Run trials in parallel
        converged = run_parallel_trials(config, trials)
        
        V_emp = converged / trials
        error = abs(V_emp - V_pred) / V_pred if V_pred > 0.05 else float('inf')
        
        print(f"{N:<6} {K:<10.4f} {V_pred:<12.2%} {V_emp:<12.2%} "
              f"{error:.1%}" if error < float('inf') else f"{N:<6} {K:<10.4f} {V_pred:<12.2%} {V_emp:<12.2%} N/A")
        
        results.append({
            'N': N,
            'V_predicted': V_pred,
            'V_empirical': V_emp,
            'error': error
        })
    
    # Check if scaling trend is correct
    print(f"\n{'='*70}")
    pred_decreasing = all(results[i]['V_predicted'] >= results[i+1]['V_predicted'] 
                         for i in range(len(results)-1))
    emp_decreasing = all(results[i]['V_empirical'] >= results[i+1]['V_empirical'] 
                        for i in range(len(results)-1))
    
    print(f"Predicted trend: {'‚úÖ Decreasing' if pred_decreasing else '‚ùå Not monotonic'}")
    print(f"Empirical trend: {'‚úÖ Decreasing' if emp_decreasing else '‚ö†Ô∏è Not monotonic (noisy)'}")
    
    mean_error = np.mean([r['error'] for r in results if r['error'] < float('inf')])
    print(f"\nMean scaling error: {mean_error:.1%}")
    
    if mean_error < 0.30 and pred_decreasing:
        print(f"‚úÖ Scaling formula validated!")
    else:
        print(f"‚ö†Ô∏è Scaling may need refinement")
    
    return results

# ============================================================================
# MAIN ENHANCED TEST
# ============================================================================

def run_enhanced_mvp():
    """
    Run the enhanced test suite focused on critical regime
    """
    print("\n" + "="*70)
    print("ENHANCED KAIABC SOFTWARE TEST")
    print("="*70)
    print("\nüéØ Goal: Test basin volume formula where it matters most")
    print("   (The critical regime, not the trivial K >> K_c case)\n")
    
    # Base configuration
    base_config = SimulationConfig(
        N=10,
        Q10=1.1,
        sigma_T=5.0,
        tau_ref=24.0,
        t_max=30*24,
        dt=0.1
    )
    
    # Test 1: Critical regime sweep
    print("TEST 1: Critical Regime Sweep")
    results, K_c = test_critical_regime(base_config, trials_per_K=50, verbose=True)
    analyze_results(results, K_c)
    
    # Test 2: Network size scaling
    print("\n" + "="*70)
    print("TEST 2: Network Size Scaling")
    scaling_results = test_network_size_scaling(
        Q10=1.1, sigma_T=5.0, K_ratio=1.5, trials=30
    )
    
    # Final recommendation
    print("\n" + "="*70)
    print("FINAL RECOMMENDATION")
    print("="*70)
    
    # Analyze transition regime specifically
    transition_results = [r for r in results if 1.0 <= r['K_ratio'] <= 1.5]
    if transition_results:
        transition_error = np.mean([r['error'] for r in transition_results 
                                   if r['error'] < float('inf')])
        
        print(f"\nCritical metric: Transition regime accuracy")
        print(f"Error in K/K_c ‚àà [1.0, 1.5]: {transition_error:.1%}")
        
        if transition_error < 0.25:
            print(f"\n‚úÖ PROCEED TO HARDWARE")
            print(f"   Recommended settings:")
            print(f"   ‚Ä¢ N = 5-10 devices")
            print(f"   ‚Ä¢ K = 1.5-2.0 √ó K_c = {1.5*K_c:.4f}-{2.0*K_c:.4f} rad/hr")
            print(f"   ‚Ä¢ Expected sync rate: 60-80%")
            print(f"   ‚Ä¢ Budget: $300-400")
        elif transition_error < 0.50:
            print(f"\n‚ö†Ô∏è PROCEED WITH CAUTION")
            print(f"   Formula works but less accurate than ideal")
            print(f"   Recommendation: Use K = 2.5√óK_c for safety")
        else:
            print(f"\n‚ùå DO NOT PROCEED TO HARDWARE")
            print(f"   Formula needs revision first")
            print(f"   Try: Alternative basin volume formulas")

def compare_formulas():
    """
    Compare different basin volume formulas against empirical data
    """
    print("\n" + "="*70)
    print("FORMULA COMPARISON TEST")
    print("="*70)
    print("\nTesting 8 different basin volume formulas:")
    print("  V1: 1 - (K_c/K)^(2N)  [Original - too optimistic]")
    print("  V2: 1 - (K_c/K)^N     [Softer exponent]")
    print("  V3: tanh((K-K_c)/(K_c*Œ≤))^N  [Smooth S-curve]")
    print("  V4: Finite-size with ‚àöN scaling  [Excellent - 8.3% error]")
    print("  V5: Sigmoid with log(N) scaling  [Failed - 17.0% error]")
    print("  V6: V4 + Metastable state correction  [Excellent - 8.8% error]")
    print("  V7: Asymmetric boundary layer  [Failed - 18.6% error]")
    print("  V8: V4 + Partial sync plateau  [CHAMPION - 6.6% error] üèÜ\n")
    
    base_config = SimulationConfig(N=10, Q10=1.1, sigma_T=5.0, tau_ref=24.0, t_max=30*24, dt=0.1)
    sigma_omega = calculate_sigma_omega(base_config.Q10, base_config.sigma_T, base_config.tau_ref)
    K_c = 2 * sigma_omega
    omega_mean = 2*np.pi / base_config.tau_ref
    
    # Extended range including below critical and transition
    K_ratios = [0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.5, 1.7, 2.0, 2.5]
    
    print(f"Running Monte Carlo trials (200 per K value for better statistics)...")
    print(f"K_c = {K_c:.4f} rad/hr\n")
    
    # Run simulations once and compare all formulas
    empirical_data = []
    for K_ratio in K_ratios:
        config = SimulationConfig(
            N=base_config.N, K=K_ratio * K_c, Q10=base_config.Q10,
            sigma_T=base_config.sigma_T, tau_ref=base_config.tau_ref,
            t_max=base_config.t_max, dt=base_config.dt
        )
        
        trials = 200  # Increased from 50 to reduce Monte Carlo variance
        converged = run_parallel_trials(config, trials)
        
        empirical_data.append({
            'K_ratio': K_ratio,
            'K': config.K,
            'V_empirical': converged / trials
        })
        
        print(f"  K/K_c = {K_ratio:.1f}: {converged}/{trials} converged ({converged/trials:.1%})")
    
    # Evaluate each formula
    print("\n" + "="*70)
    print("FORMULA PREDICTIONS vs EMPIRICAL")
    print("="*70)
    print(f"{'K/K_c':<8} {'Empirical':<10} {'V1':<8} {'V2':<8} {'V3':<8} {'V4':<8} {'V5':<8} {'V6':<8} {'V7':<8} {'V8':<8}")
    print("-" * 70)
    
    errors = {1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: []}
    
    for data in empirical_data:
        K_ratio = data['K_ratio']
        K = data['K']
        V_emp = data['V_empirical']
        
        V1 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=1)
        V2 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=2)
        V3 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=3)
        V4 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=4)
        V5 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=5)
        V6 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=6)
        V7 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=7)
        V8 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=8)
        
        print(f"{K_ratio:<8.1f} {V_emp:<10.1%} {V1:<8.1%} {V2:<8.1%} {V3:<8.1%} {V4:<8.1%} {V5:<8.1%} {V6:<8.1%} {V7:<8.1%} {V8:<8.1%}")
        
        # Calculate errors across all K values (including below critical)
        if V_emp > 0.05:  # Only calculate if empirical is meaningful
            errors[1].append(abs(V1 - V_emp))
            errors[2].append(abs(V2 - V_emp))
            errors[3].append(abs(V3 - V_emp))
            errors[4].append(abs(V4 - V_emp))
            errors[5].append(abs(V5 - V_emp))
            errors[6].append(abs(V6 - V_emp))
            errors[7].append(abs(V7 - V_emp))
            errors[8].append(abs(V8 - V_emp))
    
    # Summary - Overall performance
    print("\n" + "="*70)
    print("MEAN ABSOLUTE ERROR (all K values):")
    print("-" * 70)
    
    for version in [1, 2, 3, 4, 5, 6, 7, 8]:
        if errors[version]:
            mean_error = np.mean(errors[version])
            print(f"Formula V{version}: {mean_error:.1%}", end="")
            
            if mean_error < 0.15:
                print(f"  ‚úÖ Excellent")
            elif mean_error < 0.25:
                print(f"  ‚úÖ Good")
            elif mean_error < 0.35:
                print(f"  ‚ö†Ô∏è Acceptable")
            else:
                print(f"  ‚ùå Poor")
    
    # Transition regime specific
    print("\n" + "="*70)
    print("TRANSITION REGIME ERROR (K/K_c ‚àà [1.0, 1.5]):")
    print("-" * 70)
    
    transition_errors = {1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: []}
    for data in empirical_data:
        if 1.0 <= data['K_ratio'] <= 1.5:
            K = data['K']
            V_emp = data['V_empirical']
            
            V1 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=1)
            V2 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=2)
            V3 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=3)
            V4 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=4)
            V5 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=5)
            V6 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=6)
            V7 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=7)
            V8 = predict_basin_volume(base_config.N, sigma_omega, omega_mean, K, formula_version=8)
            
            transition_errors[1].append(abs(V1 - V_emp))
            transition_errors[2].append(abs(V2 - V_emp))
            transition_errors[3].append(abs(V3 - V_emp))
            transition_errors[4].append(abs(V4 - V_emp))
            transition_errors[5].append(abs(V5 - V_emp))
            transition_errors[6].append(abs(V6 - V_emp))
            transition_errors[7].append(abs(V7 - V_emp))
            transition_errors[8].append(abs(V8 - V_emp))
    
    for version in [1, 2, 3, 4, 5, 6, 7, 8]:
        if transition_errors[version]:
            trans_error = np.mean(transition_errors[version])
            print(f"Formula V{version}: {trans_error:.1%}", end="")
            
            if trans_error < 0.15:
                print(f"  ‚úÖ Excellent - hardware ready!")
            elif trans_error < 0.25:
                print(f"  ‚úÖ Good - safe for hardware")
            elif trans_error < 0.35:
                print(f"  ‚ö†Ô∏è Acceptable - use K=2.0√óK_c for safety")
            else:
                print(f"  ‚ùå Poor - needs refinement")
    
    # Recommend best formula
    best_version = min(transition_errors.keys(), key=lambda v: np.mean(transition_errors[v]))
    print(f"\nüèÜ BEST FORMULA: V{best_version} (mean error {np.mean(errors[best_version]):.1%})")
    
    if np.mean(errors[best_version]) < 0.25:
        print(f"\n‚úÖ HYPOTHESIS VALIDATED with V{best_version}")
        print(f"   ‚Üí Update production code to use formula V{best_version}")
        print(f"   ‚Üí Proceed to hardware with confidence")
    else:
        print(f"\n‚ö†Ô∏è Best formula still has {np.mean(errors[best_version]):.1%} error")
        print(f"   ‚Üí Consider empirical calibration")
        print(f"   ‚Üí Or test with more formula variations")

def test_hardware_regime():
    """
    PLACEHOLDER: Focused test on K/K_c ‚àà [1.1, 1.5] where hardware will operate
    
    This function will:
    1. Test only the critical transition region (K ‚âà K_c)
    2. Use higher trial count (100) for better statistics
    3. Test multiple N values (3, 5, 10) for hardware sizing
    4. Provide specific hardware recommendations
    
    Usage: python3 enhanced_test_basin_volume.py --hardware
    """
    print("\n" + "="*70)
    print("HARDWARE REGIME TEST (PLACEHOLDER)")
    print("="*70)
    print("\n‚ö†Ô∏è This function is a placeholder for future implementation.")
    print("\nWhen implemented, it will:")
    print("  ‚Ä¢ Focus on K/K_c ‚àà [1.1, 1.5] (realistic hardware coupling)")
    print("  ‚Ä¢ Test N ‚àà [3, 5, 10] (hardware budget: 3-10 nodes)")
    print("  ‚Ä¢ Run 100 trials per configuration (high confidence)")
    print("  ‚Ä¢ Use best formula from --compare results")
    print("  ‚Ä¢ Output specific recommendations:")
    print("    - Minimum K for >90% sync probability")
    print("    - Expected sync time")
    print("    - Hardware cost estimate")
    print("    - GO/NO-GO decision for $104 purchase")
    print("\nüìã To implement: Copy compare_formulas() and modify for")
    print("   high-resolution testing in transition regime only.")
    print("\nFor now, run: python3 enhanced_test_basin_volume.py --compare")
    print("="*70)

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--compare":
        compare_formulas()
    elif len(sys.argv) > 1 and sys.argv[1] == "--hardware":
        test_hardware_regime()
    else:
        run_enhanced_mvp()